# Simple workflow for deploying static content to GitHub Pages
name: Deploy content to Pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches: ["main"]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      purgeCache:
        description: "A list of URLs to purge from the cache, separated by \"|\".\n\nTo clear the entire cache, use \"--all\"."
        default: ""

      recheckUrls:
        description: "Should the existing URLs be re-checked to determine if there are any missing?"
        type: boolean
        default: false

  workflow_call:
    inputs:
      purgeCache:
        type: string
        description: "A list of URLs to purge from the cache, separated by \"|\".\n\nTo clear the entire cache, use \"--all\"."
        default: ""

      recheckUrls:
        description: "Should the existing URLs be re-checked to determine if there are any missing?"
        type: boolean
        default: false

  schedule:
    - cron: "48 0 * * *"

  repository_dispatch:
    types: [trigger_deploy]

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  actions: write
  contents: write
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Single deploy job since we're just deploying
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure mirror-metadata release exists
        uses: ./.github/actions/ensure-release
        with:
          title: "Mirror Metadata"
          tag: "mirror-metadata"
          notes: "This is used to hold metadata for the mirrored mods."

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Get username and repository
        run: |
          echo "REPO_USERNAME=${GITHUB_REPOSITORY%%/*}" >> $GITHUB_ENV
          echo "REPO_NAME=${GITHUB_REPOSITORY#*/}" >> $GITHUB_ENV
          echo "REPO_BRANCH=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}" >> $GITHUB_ENV

      - name: Set pages url
        run: |
          HOMEPAGE_URL="$(curl -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" "https://api.github.com/repos/$GITHUB_REPOSITORY/pages" | jq -r '.html_url' | sed 's/\/$//')"
          if [ "$HOMEPAGE_URL" == "null" ]; then
            echo "PAGES_URL=https://$REPO_USERNAME.github.io/$REPO_NAME" >> $GITHUB_ENV
          else
            echo "PAGES_URL=$HOMEPAGE_URL" >> $GITHUB_ENV
          fi

      - name: Set page path
        run: |
          echo "PAGES_PATH=$(echo "$PAGES_URL" | awk -F/ -v OFS="/" '{$1=$2=$3=""; print $0}' | sed 's/\/\+/\//')" >> $GITHUB_ENV

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Download cache
        if: (inputs.purgeCache != '--all')
        continue-on-error: true
        run: |
          wget "https://github.com/$GITHUB_REPOSITORY/releases/download/cache/cache.txz?`date +%s`" -O cache.txz

      - name: Download mirror metadata
        run: |
          mkdir -p downloaded_files
          wget --spider "https://github.com/$GITHUB_REPOSITORY/releases/download/mirror-metadata/metadata.json?$(date +%s)" 2>&1 | tee wget.log
          if grep -q "404 Not Found" wget.log; then
            echo '{}' > downloaded_files/metadata.json
          else
            wget "https://github.com/$GITHUB_REPOSITORY/releases/download/mirror-metadata/metadata.json?$(date +%s)" -O downloaded_files/metadata.json
          fi
          rm wget.log

      - name: Upload cache.txz
        uses: actions/upload-artifact@v4
        with:
          name: cache-backup
          path: cache.txz

      - name: Upload metadata.json
        uses: actions/upload-artifact@v4
        with:
          name: mirror-metadata-backup
          path: downloaded_files/metadata.json
          if-no-files-found: error

      - name: Delete downloaded_files
        run: |
          rm -r downloaded_files/

      - name: Extract cache
        if: (inputs.purgeCache != '--all')
        continue-on-error: true
        run: |
          tar -xJvf cache.txz

      - name: Delete cache
        if: (inputs.purgeCache != '--all')
        continue-on-error: true
        run: |
          rm cache.txz

      - name: Install npm modules
        uses: ./.github/actions/install-modules
        with:
          scripts: true
          website: true

      - name: Purge specified items from cache
        if: ((inputs.purgeCache != '') && (inputs.purgeCache != '--all'))
        run: |
          cd source/scripts
          npx tsx ./purgecache.ts "${{ inputs.purgeCache }}"

      - name: Update mirror
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p mod-mirror

          cd source/scripts
          if gh release view "mirror-metadata" --json assets --jq '.assets[].name' | grep -q "metadata.json"; then
            npx tsx ./mirror-mods.ts 2>&1
          else
            npx tsx ./mirror-mods.ts --allowEmpty 2>&1
          fi

          cd ../../mod-mirror

          # Loop through the folders in the current directory
          for dir in *; do
            if [ ! -d "$dir" ]; then
              continue
            fi

            # Check if the current directory exists as a GitHub release, else create it.
            if ! gh release view "$dir" &> /dev/null; then
              gh release create "$dir" -t "$dir" -p --notes "A release to hold mirrored mods."
            fi

            find "$dir" -type f | while read file; do
              echo "Uploading $file"
              gh release upload "$dir" "$file"
            done
          done

          if [ -f "metadata.json" ]; then
            echo "Uploading metadata.json"
            gh release upload "mirror-metadata" --clobber "metadata.json"
          fi

      - name: Trigger so-info.json update if needed
        run: |
          if ls ./mod-mirror/* 1> /dev/null 2>&1; then
            response=$(curl -s -o /dev/null -w "%{http_code}" -X POST \
              -H "Accept: application/vnd.github.v3+json" \
              -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              https://api.github.com/repos/${{ github.repository }}/actions/workflows/update-so-info.yml/dispatches \
              -d '{"ref":"${{ github.ref }}"}')
            if [ $response -ne 204 ]; then
              echo "Workflow dispatch failed with response code $response"
              exit 1
            fi
          fi

      - name: Restore so-info.json cache
        uses: actions/cache/restore@v4
        with:
          path: ./source/website/public/so-info.json
          key: so-info-
          restore-keys: so-info-

      - name: Process the json (schedule)
        if: (github.event_name == 'schedule' || inputs.recheckUrls == true)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd source/scripts
          npx tsx ./combine.ts "--baseHref=$PAGES_URL" --updateFunding --recheckUrls 2>&1 | tee ../website/public/deploy-log.txt

      - name: Process the json (normal)
        if: (github.event_name != 'schedule')
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd source/scripts
          npx tsx ./combine.ts "--baseHref=$PAGES_URL" 2>&1 | tee ../website/public/deploy-log.txt

      - name: "Archive cache"
        run: |
          tar -cJvf cache.txz \
            source/website/public/covers \
            source/website/public/funding-info.json \
            source/website/public/mod-metadata.json \

      - name: Build website
        run: |
          cd source/website
          npx astro build --base "$PAGES_PATH"

      - name: Precompress assets
        run: |
          find source/website/out -type f | while read -r file; do
            if [[ "$file" == *.html || "$file" == *.css || "$file" == *.js || "$file" == *.json ]]; then
              echo "$file"
              brotli -k -q 11 "$file"
            fi
          done

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          # Upload entire repository
          path: "./source/website/out"

      - name: Ensure cache release exists
        uses: ./.github/actions/ensure-release
        with:
          title: "Deployment Cache"
          tag: "cache"
          notes: "This is used to hold data between page deployments."

      - name: Push cache
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh release upload cache --clobber "cache.txz"

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
